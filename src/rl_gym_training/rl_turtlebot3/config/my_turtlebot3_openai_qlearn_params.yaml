turtlebot3:
    
    # Q-Learning parameters:
    alpha: 0.01
    gamma: 0.9
    epsilon: 1.0
    epsilon_discount: 0.999
    nepisodes: 100000
    nsteps: 100000 # creo que no se usa esto porque lo tiene implicito en el registro del entorno

    # Actions parameters:
    n_actions: 3 # We have 3 actions, Forwards,TurnLeft,TurnRight

    linear_forward_speed: 0.3 # Speed for ging fowards
    linear_turn_speed: 0.05 # Lienar speed when turning
    angular_speed: 0.3 # Angular speed when turning Left or Right

    step_time: 0.2 # Number of seconds (in real time) a step takes, that is, the time we wait until we can perform another action
    reset_time: 0.5 # Number of seconds (in real time) we wait until the robot reaches its final state (in reset phases)

    # Observation parameters:
    angle_ranges: [[-90,-54],[-54,-18],[-18,18],[18,54],[54,90]] # Laser scan angle intervals taken into account for each observation value
    distance_ranges: [0.5,1.0] # maximum distances to discretize laser readings
    min_range: 0.15 # Minimum meters below wich we consider we have crashed

    # Rewards:
    forward_reward: 2 # Points Given to go forwards
    turn_reward: -1 # Points Given to turn as action
    end_episode_points: -200 # Points given when ending an episode
    
    # Initial states:
    init_linear_forward_speed: 0.0 # Initial linear speed in which we start each episode
    init_linear_turn_speed: 0.0 # Initial angular speed in shich we start each episode
    initial_poses: [[-1.0,-2.0,1.0,1.0],[0.0,-2.0,1.0,1.0],[1.0,-2.0,1.0,1.0],[-1.0,2.0,-1.0,1.0],[0.0,2.0,-1.0,1.0],[1.0,2.0,-1.0,1.0],
                    [-2.0,-1.0,0.0,-1.0],[-2.0,0.0,0.0,-1.0],[-2.0,1.0,0.0,-1.0],[2.0,-1.0,1.0,0.0],[2.0,0.0,1.0,0.0],[2.0,1.0,1.0,0.0]]

